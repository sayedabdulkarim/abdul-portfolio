# Model Configuration
MODEL_TYPE=ollama  # Options: ollama, llamacpp, replicate, huggingface

# For Local Testing with Ollama (Recommended)
OLLAMA_MODEL=abdul-llama

# For Local Testing with llama.cpp
MODEL_PATH=./models/abdul-llama.gguf

# Replicate API (for hosted fine-tuned model)
REPLICATE_API_TOKEN=your_replicate_token_here
REPLICATE_MODEL=your-username/sarim-llama-3.2-1b  # Your fine-tuned model

# Hugging Face (alternative)
HUGGINGFACE_TOKEN=your_hf_token_here
HUGGINGFACE_MODEL=your-username/sarim-llama-3.2-1b

# OpenAI (optional, for comparison)
OPENAI_API_KEY=your_openai_key_here

# Redis Cache (optional, for production)
REDIS_URL=redis://localhost:6379

# CORS Settings
FRONTEND_URL=http://localhost:3000
PRODUCTION_URL=https://sayedabdulkarim.github.io